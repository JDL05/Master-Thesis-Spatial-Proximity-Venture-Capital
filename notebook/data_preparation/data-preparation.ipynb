{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edcc8bf6f790174",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7762d7373e4b5f3",
   "metadata": {},
   "source": [
    "## A: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b74fe78267e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:19.843355Z",
     "start_time": "2025-05-10T21:39:19.386178Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "from dotenv import load_dotenv\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "import requests\n",
    "import math\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"geocage\")\n",
    "\n",
    "os.chdir('/Users/janlinzner/Projects/Master-Thesis-Spatial-Proximity-Venture-Capital')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a4aae1abf7805",
   "metadata": {},
   "source": [
    "## B: Companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c7f9c4bbf6b32",
   "metadata": {},
   "source": [
    "### Append all CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a74c0c08ce10a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:20.147436Z",
     "start_time": "2025-05-10T21:39:19.852512Z"
    }
   },
   "outputs": [],
   "source": [
    "root_directory = 'data/companies'\n",
    "\n",
    "df_list = []\n",
    "\n",
    "selected_columns = [\n",
    "    \"Organization Name\", \"Organization Name URL\", \"Industry Groups\", \"Headquarters Location\",\n",
    "    \"Founded Date\", \"Founded Date Precision\", \"Exit Date\", \"Exit Date Precision\", \"Number of Founders\", \"Founders\",\n",
    "    \"Last Equity Funding Amount (in USD)\", \"Last Equity Funding Type\",\n",
    "]\n",
    "\n",
    "for subdir, _, _ in os.walk(root_directory):\n",
    "    csv_files = glob.glob(os.path.join(subdir, '*.csv'))\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "companies = final_df[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf702c4371f17aea",
   "metadata": {},
   "source": [
    "### Convert variables to date variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83087bf9f3bcae1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:20.244598Z",
     "start_time": "2025-05-10T21:39:20.236Z"
    }
   },
   "outputs": [],
   "source": [
    "date_cols = ['Founded Date', 'Exit Date']\n",
    "for col in date_cols:\n",
    "    companies[col] = pd.to_datetime(companies[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11f67666df3115",
   "metadata": {},
   "source": [
    "### Add Founding Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2aa3ffeda2e718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:20.273898Z",
     "start_time": "2025-05-10T21:39:20.270169Z"
    }
   },
   "outputs": [],
   "source": [
    "founded_year = companies['Founded Date'].dt.year\n",
    "\n",
    "pos = companies.columns.get_loc('Founded Date') + 1\n",
    "companies.insert(loc=pos, column='Founded Year', value=founded_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c52a7e0d24ba83",
   "metadata": {},
   "source": [
    "### Convert variables to categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154aed128da65a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:20.310182Z",
     "start_time": "2025-05-10T21:39:20.304954Z"
    }
   },
   "outputs": [],
   "source": [
    "companies['Founded Date Precision'] = pd.Categorical(companies['Founded Date Precision'],\n",
    "                                    categories=['month','year','day'],\n",
    "                                    ordered=False)\n",
    "\n",
    "companies['Exit Date Precision'] = pd.Categorical(companies['Exit Date Precision'],\n",
    "                                    categories=['day','month'],\n",
    "                                    ordered=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb348f2c51645bde",
   "metadata": {},
   "source": [
    "### Provide a company id with leading zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c53e3e553ef96d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:20.351386Z",
     "start_time": "2025-05-10T21:39:20.339209Z"
    }
   },
   "outputs": [],
   "source": [
    "companies.reset_index(drop=True, inplace=True)\n",
    "companies['Company ID'] = companies.index + 1\n",
    "companies['Company ID'] = companies['Company ID'].apply(lambda x: f\"{x:06d}\")\n",
    "companies['Company ID'] = companies['Company ID'].astype('string')\n",
    "\n",
    "cols = ['Company ID'] + [c for c in companies.columns if c != 'Company ID']\n",
    "companies = companies[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716dcc915fe8e39",
   "metadata": {},
   "source": [
    "### Convert company events into binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7edf04f2b944c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:20.393156Z",
     "start_time": "2025-05-10T21:39:20.382116Z"
    }
   },
   "outputs": [],
   "source": [
    "companies = companies.copy()\n",
    "\n",
    "companies.loc[:, 'Exit Binary']     = companies['Exit Date'].notna().astype(int)\n",
    "companies['Exit Binary'] = companies['Exit Binary'].astype(bool)\n",
    "\n",
    "order = [\n",
    "    'Company ID', 'Organization Name', 'Organization Name URL', 'Industry Groups', 'Headquarters Location',\n",
    "    'Founded Date', 'Founded Date Precision', 'Founded Year', 'Exit Date', 'Exit Date Precision', 'Exit Binary',\n",
    "    'Number of Founders', 'Founders', 'Last Equity Funding Amount (in USD)',\n",
    "    'Last Equity Funding Type'\n",
    "]\n",
    "companies = companies[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997401d5fb152d1",
   "metadata": {},
   "source": [
    "### Adding geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331178d90281bf5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:20.814166Z",
     "start_time": "2025-05-10T21:39:20.422939Z"
    }
   },
   "outputs": [],
   "source": [
    "cache_file = 'data/locations/location_cache.csv'\n",
    "\n",
    "if not os.path.exists(cache_file):\n",
    "    pd.DataFrame({\n",
    "        'hq_location': pd.Series(dtype='object'),\n",
    "        'latitude':     pd.Series(dtype='float64'),\n",
    "        'longitude':    pd.Series(dtype='float64'),\n",
    "    }).to_csv(cache_file, index=False)\n",
    "    print(f\"Created new file: {cache_file}\")\n",
    "else:\n",
    "    print(f\"File already exists: {cache_file}\")\n",
    "\n",
    "cached_coords = pd.read_csv(cache_file)\n",
    "\n",
    "unique_locations = companies['Headquarters Location'].dropna().unique()\n",
    "total = len(unique_locations)\n",
    "base_url = \"https://api.opencagedata.com/geocode/v1/json\"\n",
    "api_key   = os.getenv(\"geocage\")\n",
    "\n",
    "coords_list = []\n",
    "for idx, location in enumerate(unique_locations, start=1):\n",
    "\n",
    "    cached = cached_coords[cached_coords['hq_location'] == location]\n",
    "    if not cached.empty:\n",
    "        row = cached.iloc[0].to_dict()\n",
    "        coords_list.append(row)\n",
    "        print(f\"[{idx}/{total}] (cached)  {location} → {row['latitude']}, {row['longitude']}\")\n",
    "        continue\n",
    "\n",
    "    if not location.strip():\n",
    "        row = {'hq_location': location, 'latitude': None, 'longitude': None}\n",
    "        coords_list.append(row)\n",
    "        print(f\"[{idx}/{total}] (blank)   {location!r} → None\")\n",
    "    else:\n",
    "\n",
    "        params = {\"key\": api_key, \"q\": location, \"limit\": 1, \"no_annotations\": 1}\n",
    "        try:\n",
    "            resp = requests.get(base_url, params=params)\n",
    "            data = resp.json()\n",
    "            if data['status']['code'] == 200 and data['results']:\n",
    "                lat = data['results'][0]['geometry']['lat']\n",
    "                lng = data['results'][0]['geometry']['lng']\n",
    "            else:\n",
    "                lat = lng = None\n",
    "        except Exception:\n",
    "            lat = lng = None\n",
    "\n",
    "        row = {'hq_location': location, 'latitude': lat, 'longitude': lng}\n",
    "        coords_list.append(row)\n",
    "        print(f\"[{idx}/{total}] (fetched) {location} → {lat}, {lng}\")\n",
    "\n",
    "    new_row_df = pd.DataFrame([row])\n",
    "    if cached_coords.empty:\n",
    "        cached_coords = new_row_df\n",
    "    else:\n",
    "        cached_coords = pd.concat([cached_coords, new_row_df], ignore_index=True)\n",
    "    cached_coords = cached_coords.drop_duplicates(subset='hq_location', keep='first')\n",
    "    cached_coords.to_csv(cache_file, index=False)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "df_coords = pd.DataFrame(coords_list)\n",
    "companies = companies.merge(\n",
    "    df_coords,\n",
    "    left_on='Headquarters Location',\n",
    "    right_on='hq_location',\n",
    "    how='left'\n",
    ").drop(columns=['hq_location'])\n",
    "\n",
    "lat = companies.pop('latitude')\n",
    "lon = companies.pop('longitude')\n",
    "\n",
    "insert_at = companies.columns.get_loc('Headquarters Location') + 1\n",
    "\n",
    "companies.insert(insert_at, 'latitude', lat)\n",
    "companies.insert(insert_at + 1, 'longitude', lon)\n",
    "\n",
    "companies = (\n",
    "    companies\n",
    "      .rename(columns={\n",
    "          'latitude':  'Latitude',\n",
    "          'longitude': 'Longitude'\n",
    "      })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe89758d4fea13",
   "metadata": {},
   "source": [
    "### Startup Hub\n",
    "https://www.startupblink.com <br>\n",
    "Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fb6395fd5cf6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:35.668026Z",
     "start_time": "2025-05-10T21:39:20.841210Z"
    }
   },
   "outputs": [],
   "source": [
    "geocoder = OpenCageGeocode(api_key)\n",
    "\n",
    "hotspot_names = [\n",
    "    \"London, United Kingdom\", \"Paris, France\", \"Berlin, Germany\",\n",
    "    \"Stockholm, Sweden\", \"Munich, Germany\", \"Helsinki, Finland\",\n",
    "    \"Madrid, Spain\", \"Dublin, Ireland\", \"Tallinn, Estonia\",\n",
    "    \"Copenhagen, Denmark\", \"Milan, Italy\", \"Zurich, Switzerland\",\n",
    "    \"Oslo, Norway\", \"Cambridge, United Kingdom\", \"Kyiv, Ukraine\",\n",
    "    \"Vienna, Austria\", \"Brussels, Belgium\", \"Manchester, United Kingdom\",\n",
    "    \"Lisbon, Portugal\", \"Prague, Czech Republic\", \"Warsaw, Poland\",\n",
    "    \"Hamburg, Germany\", \"Oxford, United Kingdom\", \"Amsterdam, The Netherlands\", \"Barcelona, Spain\", \"Lausanne, Switzerland\",\n",
    "]\n",
    "\n",
    "records = []\n",
    "for name in hotspot_names:\n",
    "    results = geocoder.geocode(name, limit=5)\n",
    "    if results:\n",
    "        best = max(results, key=lambda x: x.get(\"confidence\", 0))\n",
    "        geom = best[\"geometry\"]\n",
    "        records.append({\n",
    "            \"city\": name.split(\",\", 1)[0],\n",
    "            \"lat\":  geom[\"lat\"],\n",
    "            \"lng\":  geom[\"lng\"]\n",
    "        })\n",
    "    time.sleep(0.2)  # rate‐limit\n",
    "hotspots_df = pd.DataFrame(records)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2\n",
    "    return R * 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "def min_dist_to_hotspot(lat, lon):\n",
    "    return hotspots_df.apply(\n",
    "        lambda r: haversine(lat, lon, r[\"lat\"], r[\"lng\"]), axis=1\n",
    "    ).min()\n",
    "\n",
    "companies[\"Latitude\"]  = pd.to_numeric(companies[\"Latitude\"],  errors=\"coerce\")\n",
    "companies[\"Longitude\"] = pd.to_numeric(companies[\"Longitude\"], errors=\"coerce\")\n",
    "\n",
    "companies[\"Distance to Hub\"] = companies.apply(\n",
    "    lambda r: min_dist_to_hotspot(r[\"Latitude\"], r[\"Longitude\"]), axis=1\n",
    ")\n",
    "companies[\"Hub Binary\"] = (companies[\"Distance to Hub\"] < 20).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb69580",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoder = OpenCageGeocode(api_key)\n",
    "\n",
    "hotspot_names = [\n",
    "    \"London, United Kingdom\", \"Paris, France\", \"Berlin, Germany\",\n",
    "    \"Stockholm, Sweden\", \"Munich, Germany\", \"Helsinki, Finland\",\n",
    "    \"Madrid, Spain\", \"Dublin, Ireland\", \"Tallinn, Estonia\",\n",
    "    \"Copenhagen, Denmark\", \"Milan, Italy\", \"Zurich, Switzerland\",\n",
    "    \"Oslo, Norway\", \"Cambridge, United Kingdom\", \"Kyiv, Ukraine\",\n",
    "    \"Vienna, Austria\", \"Brussels, Belgium\", \"Manchester, United Kingdom\",\n",
    "    \"Lisbon, Portugal\", \"Prague, Czech Republic\", \"Warsaw, Poland\",\n",
    "    \"Hamburg, Germany\", \"Oxford, United Kingdom\", \"Amsterdam, The Netherlands\", \"Barcelona, Spain\", \"Lausanne, Switzerland\",\n",
    "]\n",
    "\n",
    "records = []\n",
    "for name in hotspot_names:\n",
    "    city, country = [s.strip() for s in name.split(\",\", 1)]\n",
    "    results = geocoder.geocode(name, limit=5)\n",
    "    if results:\n",
    "        best = max(results, key=lambda x: x.get(\"confidence\", 0))\n",
    "        geom = best[\"geometry\"]\n",
    "        records.append({\n",
    "            \"city\":    city,\n",
    "            \"country\": country,\n",
    "            \"lat\":     geom[\"lat\"],\n",
    "            \"lng\":     geom[\"lng\"]\n",
    "        })\n",
    "    time.sleep(0.2)  # respect rate‐limit\n",
    "\n",
    "hotspots_df = pd.DataFrame(records)\n",
    "\n",
    "hotspots_df.to_csv(\"data/sets-for-r/startup_hubs.csv\", index=False)\n",
    "\n",
    "print(\"Wrote\", len(hotspots_df), \"hubs to startup_hubs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a8f934f6e267",
   "metadata": {},
   "source": [
    "### Print final companies dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c436eced179249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:35.704868Z",
     "start_time": "2025-05-10T21:39:35.694327Z"
    }
   },
   "outputs": [],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca034f32c54022c",
   "metadata": {},
   "source": [
    "## C: Rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ae4b79657df75",
   "metadata": {},
   "source": [
    "### Append all CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593daf74b563916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:36.226373Z",
     "start_time": "2025-05-10T21:39:35.830506Z"
    }
   },
   "outputs": [],
   "source": [
    "root_directory = 'data/rounds'\n",
    "\n",
    "selected_columns = [\n",
    "    'Transaction Name', 'Transaction Name URL', 'Organization Name', 'Organization Name URL', 'Funding Type', 'Money Raised (in USD)', 'Announced Date', 'Lead Investors', 'Investor Names', 'Number of Investors',\n",
    "]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for subdir, _, _ in os.walk(root_directory):\n",
    "    csv_files = glob.glob(os.path.join(subdir, '*.csv'))\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "rounds = final_df[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0607e504d63b5e7",
   "metadata": {},
   "source": [
    "### Convert variables to date variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154343210444aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:36.280152Z",
     "start_time": "2025-05-10T21:39:36.269868Z"
    }
   },
   "outputs": [],
   "source": [
    "date_cols = ['Announced Date']\n",
    "for col in date_cols:\n",
    "    rounds[col] = pd.to_datetime(rounds[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b5e443d9ba4f6",
   "metadata": {},
   "source": [
    "### Add round id with leading zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540be2e2a36a248f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:36.426981Z",
     "start_time": "2025-05-10T21:39:36.408118Z"
    }
   },
   "outputs": [],
   "source": [
    "rounds.reset_index(drop=True, inplace=True)\n",
    "rounds['Round ID'] = rounds.index + 1\n",
    "rounds['Round ID'] = rounds['Round ID'].apply(lambda x: f\"{x:06d}\")\n",
    "rounds['Round ID'] = rounds['Round ID'].astype('string')\n",
    "\n",
    "cols = ['Round ID'] + [c for c in rounds.columns if c != 'Round ID']\n",
    "rounds = rounds[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eeaca2e6539253",
   "metadata": {},
   "source": [
    "## D: Investors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9215e1b9d4ce2",
   "metadata": {},
   "source": [
    "### Append all CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5eb49e92d30c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:36.573085Z",
     "start_time": "2025-05-10T21:39:36.469254Z"
    }
   },
   "outputs": [],
   "source": [
    "root_directory = 'data/investors'\n",
    "df_list = []\n",
    "\n",
    "selected_columns = [\n",
    "    \"Organization/Person Name\", \"Organization/Person Name URL\", \"Investor Type\",\n",
    "    \"Number of Investments\", \"Number of Exits\", \"Location\",\n",
    "    \"Description\", \"Number of Lead Investments\",\n",
    "    \"Number of Portfolio Organizations\", \"Founded Date\", \"Industry Groups\",\n",
    "]\n",
    "\n",
    "for subdir, _, _ in os.walk(root_directory):\n",
    "    csv_files = glob.glob(os.path.join(subdir, '*.csv'))\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "investors = final_df[selected_columns].copy()\n",
    "\n",
    "investors.drop_duplicates(\n",
    "    subset=['Organization/Person Name', 'Organization/Person Name URL'],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7ef7cb0ad9f8b",
   "metadata": {},
   "source": [
    "### Convert variables to date variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71330ce1f08e672c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:36.598302Z",
     "start_time": "2025-05-10T21:39:36.593451Z"
    }
   },
   "outputs": [],
   "source": [
    "date_cols = ['Founded Date']\n",
    "for col in date_cols:\n",
    "    investors[col] = pd.to_datetime(investors[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83df2caa68a08c2",
   "metadata": {},
   "source": [
    "### Add investor id with leading zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c621484a59b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:36.623632Z",
     "start_time": "2025-05-10T21:39:36.618663Z"
    }
   },
   "outputs": [],
   "source": [
    "investors.reset_index(drop=True, inplace=True)\n",
    "investors['Investor ID'] = investors.index + 1\n",
    "investors['Investor ID'] = investors['Investor ID'].apply(lambda x: f\"{x:06d}\")\n",
    "investors['Investor ID'] = investors['Investor ID'].astype('string')\n",
    "\n",
    "cols = ['Investor ID'] + [c for c in investors.columns if c != 'Investor ID']\n",
    "investors = investors[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83bcb95420fc5f5",
   "metadata": {},
   "source": [
    "### Adding Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293a89bc734be17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:36.908805Z",
     "start_time": "2025-05-10T21:39:36.644235Z"
    }
   },
   "outputs": [],
   "source": [
    "cache_file = 'data/locations/location_cache.csv'\n",
    "if not os.path.exists(cache_file):\n",
    "    pd.DataFrame({\n",
    "        'hq_location': pd.Series(dtype='object'),\n",
    "        'latitude':     pd.Series(dtype='float64'),\n",
    "        'longitude':    pd.Series(dtype='float64'),\n",
    "    }).to_csv(cache_file, index=False)\n",
    "    print(f\"Created new file: {cache_file}\")\n",
    "else:\n",
    "    print(f\"File already exists: {cache_file}\")\n",
    "\n",
    "cached_coords = pd.read_csv(cache_file)\n",
    "\n",
    "unique_locations = investors['Location'].dropna().unique()\n",
    "total = len(unique_locations)\n",
    "base_url = \"https://api.opencagedata.com/geocode/v1/json\"\n",
    "api_key   = os.getenv(\"geocage\")\n",
    "\n",
    "coords_list = []\n",
    "for idx, location in enumerate(unique_locations, start=1):\n",
    "\n",
    "    cached = cached_coords[cached_coords['hq_location'] == location]\n",
    "    if not cached.empty:\n",
    "        row = cached.iloc[0].to_dict()\n",
    "        coords_list.append(row)\n",
    "        print(f\"[{idx}/{total}] (cached)  {location} → {row['latitude']}, {row['longitude']}\")\n",
    "        continue\n",
    "\n",
    "    if not location.strip():\n",
    "        row = {'hq_location': location, 'latitude': None, 'longitude': None}\n",
    "        coords_list.append(row)\n",
    "        print(f\"[{idx}/{total}] (blank)   {location!r} → None\")\n",
    "    else:\n",
    "\n",
    "        params = {\"key\": api_key, \"q\": location, \"limit\": 1, \"no_annotations\": 1}\n",
    "        try:\n",
    "            resp = requests.get(base_url, params=params)\n",
    "            data = resp.json()\n",
    "            if data['status']['code'] == 200 and data['results']:\n",
    "                lat = data['results'][0]['geometry']['lat']\n",
    "                lng = data['results'][0]['geometry']['lng']\n",
    "            else:\n",
    "                lat = lng = None\n",
    "        except Exception:\n",
    "            lat = lng = None\n",
    "\n",
    "        row = {'hq_location': location, 'latitude': lat, 'longitude': lng}\n",
    "        coords_list.append(row)\n",
    "        print(f\"[{idx}/{total}] (fetched) {location} → {lat}, {lng}\")\n",
    "\n",
    "    new_row_df = pd.DataFrame([row])\n",
    "    cached_coords = pd.concat([cached_coords, new_row_df], ignore_index=True)\n",
    "    cached_coords = cached_coords.drop_duplicates(subset='hq_location', keep='first')\n",
    "    cached_coords.to_csv(cache_file, index=False)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "df_coords = pd.DataFrame(coords_list)\n",
    "\n",
    "investors = investors.merge(\n",
    "    df_coords,\n",
    "    left_on='Location',\n",
    "    right_on='hq_location',\n",
    "    how='left'\n",
    ").drop(columns=['hq_location'])\n",
    "\n",
    "lat = investors.pop('latitude')\n",
    "lon = investors.pop('longitude')\n",
    "insert_at = investors.columns.get_loc('Location') + 1\n",
    "investors.insert(insert_at,     'Latitude',  lat)\n",
    "investors.insert(insert_at + 1, 'Longitude', lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a87fc4f099539",
   "metadata": {},
   "source": [
    "### Add zeros for NaN in Lead Investments and Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831cef1cd265848",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:36.940633Z",
     "start_time": "2025-05-10T21:39:36.937586Z"
    }
   },
   "outputs": [],
   "source": [
    "investors['Number of Lead Investments'] = investors['Number of Lead Investments'].fillna(0)\n",
    "investors['Number of Exits'] = investors['Number of Exits'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "investors.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c08ba05825d7e",
   "metadata": {},
   "source": [
    "### Extract Descriptions to classify it if it is a sector specific investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6402f563e64f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:37.007373Z",
     "start_time": "2025-05-10T21:39:36.981566Z"
    }
   },
   "outputs": [],
   "source": [
    "focus_path = 'data/industry-focus/industry_focus_save.csv'\n",
    "existing = pd.read_csv(focus_path)\n",
    "\n",
    "merged = investors.merge(\n",
    "    existing[['Organization/Person Name', 'Organization/Person Name URL', 'Specific VC Binary']],\n",
    "    on=['Organization/Person Name', 'Organization/Person Name URL'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "annot_df = merged[[\n",
    "    'Organization/Person Name',\n",
    "    'Description',\n",
    "    'Organization/Person Name URL',\n",
    "    'Specific VC Binary'\n",
    "]].copy()\n",
    "\n",
    "annot_df['Specific VC Binary'] = annot_df['Specific VC Binary'] \\\n",
    "    .map({1: '1', 0: '0'}) \\\n",
    "    .fillna('')\n",
    "\n",
    "to_annotate = annot_df[annot_df['Specific VC Binary'] == '']\n",
    "\n",
    "to_annotate.to_csv(\n",
    "    'data/industry-focus/industry_focus.csv',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c323b57b347ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:37.047027Z",
     "start_time": "2025-05-10T21:39:37.027845Z"
    }
   },
   "outputs": [],
   "source": [
    "industry_focus = pd.read_csv('data/industry-focus/industry_focus_save.csv')\n",
    "\n",
    "investors = investors.merge(\n",
    "    industry_focus[['Organization/Person Name',\n",
    "                    'Organization/Person Name URL',\n",
    "                    'Specific VC Binary']],\n",
    "    on=['Organization/Person Name', 'Organization/Person Name URL'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "investors['Specific VC Binary'] = (\n",
    "    investors['Specific VC Binary']\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    "    .astype('boolean')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a80d5",
   "metadata": {},
   "source": [
    "### Extract Investor Type\n",
    "Search the 'Investor Type' column and if there is one of the Types, put a True in the assigned Boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdc03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_types(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [t.strip().lower() for t in x]\n",
    "\n",
    "    return [t.strip().lower() for t in x.split(\",\")]\n",
    "\n",
    "\n",
    "keywords = {\n",
    "    \"accelerator\":              \"Accelerator\",\n",
    "    \"micro vc\":                 \"Micro VC\",\n",
    "    \"corporate venture capital\":\"Corporate Venture Capital\",\n",
    "    \"angel group\":              \"Angel Group\"\n",
    "}\n",
    "\n",
    "investors[\"type_list\"] = investors[\"Investor Type\"].apply(parse_types)\n",
    "\n",
    "for kw, col in keywords.items():\n",
    "    investors[col] = investors[\"type_list\"].apply(lambda lst: kw in lst)\n",
    "\n",
    "investors.drop(columns=\"type_list\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e06c09bae2452c",
   "metadata": {},
   "source": [
    "### Print final investors dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfee573a0746c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:37.076280Z",
     "start_time": "2025-05-10T21:39:37.069460Z"
    }
   },
   "outputs": [],
   "source": [
    "investors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb40b0bee74ded4",
   "metadata": {},
   "source": [
    "## E: Seed Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604fb94c027725b",
   "metadata": {},
   "source": [
    "### Seed - Help Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee4b5dd",
   "metadata": {},
   "source": [
    "Create Industry Group Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d76102",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies['Industry Groups'] = companies['Industry Groups'].fillna('').str.replace(r'\\s*,\\s*', ',', regex=True)\n",
    "dummies = companies['Industry Groups'].str.get_dummies(sep=',').astype(bool)\n",
    "companies = pd.concat([companies, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9dfba0",
   "metadata": {},
   "source": [
    "Delete companies from the Blockchain environment due to different characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ece97",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = companies[~companies['Blockchain and Cryptocurrency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4680bb4384e5c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:38.173622Z",
     "start_time": "2025-05-10T21:39:37.138862Z"
    }
   },
   "outputs": [],
   "source": [
    "round_type_col = 'Funding Type'\n",
    "seed_rounds = rounds[rounds[round_type_col].isin(['Seed', 'Pre-Seed', 'Angel'])].copy()\n",
    "\n",
    "company_lookup = {\n",
    "    (str(n).strip().lower(), str(u).strip().lower()): cid\n",
    "    for n, u, cid in zip(\n",
    "        companies['Organization Name'],\n",
    "        companies['Organization Name URL'],\n",
    "        companies['Company ID']\n",
    "    )\n",
    "}\n",
    "\n",
    "investor_lookup = {\n",
    "    str(n).strip().lower(): (iid, str(url).strip())\n",
    "    for n, iid, url in zip(\n",
    "        investors['Organization/Person Name'],\n",
    "        investors['Investor ID'],\n",
    "        investors['Organization/Person Name URL']\n",
    "    )\n",
    "}\n",
    "\n",
    "seed_rounds['comp_key'] = seed_rounds.apply(\n",
    "    lambda r: (str(r['Organization Name']).strip().lower(),\n",
    "               str(r['Organization Name URL']).strip().lower()),\n",
    "    axis=1\n",
    ")\n",
    "seed_rounds = seed_rounds[seed_rounds['comp_key'].isin(company_lookup)].copy()\n",
    "seed_rounds.drop(columns=['comp_key'], inplace=True)\n",
    "\n",
    "records = []\n",
    "for _, row in seed_rounds.iterrows():\n",
    "    rid = row['Round ID']\n",
    "    org_name = row['Organization Name']\n",
    "    org_url = row['Organization Name URL']\n",
    "    comp_key = (org_name.strip().lower(), org_url.strip().lower())\n",
    "    company_id = company_lookup[comp_key]\n",
    "    lead_raw = row.get('Lead Investors', '')\n",
    "    lead_list = [inv.strip() for inv in str(lead_raw).split(',') if pd.notna(lead_raw) and inv.strip().lower()!='nan']\n",
    "    inv_raw = row.get('Investor Names', '')\n",
    "    inv_list = [inv.strip() for inv in str(inv_raw).split(',') if pd.notna(inv_raw) and inv.strip().lower()!='nan']\n",
    "    for inv_name in set(lead_list + inv_list):\n",
    "        lookup = investor_lookup.get(inv_name.lower())\n",
    "        if not lookup:\n",
    "            continue\n",
    "        inv_id, inv_url = lookup\n",
    "        records.append({\n",
    "            'Round ID':               rid,\n",
    "            'Company ID':             company_id,\n",
    "            'Organization Name':      org_name,\n",
    "            'Organization Name URL':  org_url,\n",
    "            'Investor ID':            inv_id,\n",
    "            'Investor Name':          inv_name,\n",
    "            'Investor URL':           inv_url,\n",
    "            'Lead':                   inv_name in lead_list\n",
    "        })\n",
    "\n",
    "seed_help = pd.DataFrame(records)\n",
    "\n",
    "investor_extra = [\n",
    "    'Number of Investments',\n",
    "    'Number of Portfolio Organizations',\n",
    "    'Number of Lead Investments',\n",
    "    'Number of Exits',\n",
    "    'Longitude',\n",
    "    'Latitude',\n",
    "    'Founded Date',\n",
    "    'Specific VC Binary',\n",
    "    'Accelerator',\n",
    "    'Micro VC',\n",
    "    'Angel Group',\n",
    "    'Corporate Venture Capital'\n",
    "]\n",
    "seed_help = seed_help.merge(\n",
    "    investors[['Investor ID'] + investor_extra],\n",
    "    on='Investor ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "company_extra = ['Longitude', 'Latitude', 'Founded Year']\n",
    "seed_help = seed_help.merge(\n",
    "    companies[['Company ID'] + company_extra],\n",
    "    on='Company ID',\n",
    "    how='left',\n",
    "    suffixes=('', '_comp')\n",
    ")\n",
    "\n",
    "rename_map = {\n",
    "    'Longitude':           'Investor Longitude',\n",
    "    'Latitude':            'Investor Latitude',\n",
    "    'Longitude_comp':      'Company Longitude',\n",
    "    'Latitude_comp':       'Company Latitude',\n",
    "    'Founded Date':       'Investor Founded Date',\n",
    "    'Founded Year':      'Organization Founded Year',\n",
    "}\n",
    "seed_help.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "cols_order = [\n",
    "    'Round ID',\n",
    "    'Company ID',\n",
    "    'Organization Name',\n",
    "    'Organization Name URL',\n",
    "    'Organization Founded Year',\n",
    "    'Investor ID',\n",
    "    'Investor Name',\n",
    "    'Investor URL',\n",
    "    'Investor Founded Date',\n",
    "    'Investor Longitude',\n",
    "    'Investor Latitude',\n",
    "    'Company Longitude',\n",
    "    'Company Latitude',\n",
    "    'Number of Investments',\n",
    "    'Number of Portfolio Organizations',\n",
    "    'Number of Lead Investments',\n",
    "    'Number of Exits',\n",
    "    'Lead',\n",
    "    'Specific VC Binary',\n",
    "    'Accelerator',\n",
    "    'Angel Group',\n",
    "    'Micro VC',\n",
    "    'Corporate Venture Capital'\n",
    "]\n",
    "seed_help = seed_help[cols_order]\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1)*math.cos(lat2)*math.sin(dlon/2)**2\n",
    "    c = 2*math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "seed_help['Distance km'] = seed_help.apply(\n",
    "    lambda r: haversine(\n",
    "        r['Investor Latitude'], r['Investor Longitude'],\n",
    "        r['Company Latitude'], r['Company Longitude']\n",
    "    ), axis=1\n",
    ")\n",
    "seed_help['Local Investor'] = seed_help['Distance km'] < 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b90662b8f5bc89",
   "metadata": {},
   "source": [
    "### Create features to companies dataframe about seed round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557485d74b600fe6",
   "metadata": {},
   "source": [
    "#### Number of Seed Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e018ea6d5532d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:38.240633Z",
     "start_time": "2025-05-10T21:39:38.219409Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = seed_help.groupby('Company ID')['Round ID'].nunique().rename('Number Seed Rounds')\n",
    "companies = companies.merge(counts, on='Company ID', how='left')\n",
    "companies['Number Seed Rounds'] = companies['Number Seed Rounds'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443445238130a3da",
   "metadata": {},
   "source": [
    "#### Average Distance to Seed Investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498375933b1cf17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:38.366317Z",
     "start_time": "2025-05-10T21:39:38.351331Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_distance = seed_help.groupby('Company ID')['Distance km'].mean().rename('Avg Seed Investor Distance')\n",
    "companies = companies.merge(avg_distance, on='Company ID', how='left')\n",
    "companies['Avg Seed Investor Distance'] = companies['Avg Seed Investor Distance'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8312bf81ee53b37",
   "metadata": {},
   "source": [
    "#### Average Portfolio Organizations of Investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87caa18294b3e521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:38.424595Z",
     "start_time": "2025-05-10T21:39:38.400583Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_help['Number of Portfolio Organizations'] = pd.to_numeric(\n",
    "    seed_help['Number of Portfolio Organizations'],\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "avg_portfolio = (\n",
    "    seed_help\n",
    "    .groupby('Company ID')['Number of Portfolio Organizations']\n",
    "    .mean()\n",
    "    .rename('Average Seed Investors Portfolio Organizations')\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    avg_portfolio,\n",
    "    on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "companies['Average Seed Investors Portfolio Organizations'] = (\n",
    "    companies['Average Seed Investors Portfolio Organizations']\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f86fefa2726e2",
   "metadata": {},
   "source": [
    "#### Number of Seed Investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f11ee13b261ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:38.471180Z",
     "start_time": "2025-05-10T21:39:38.455212Z"
    }
   },
   "outputs": [],
   "source": [
    "num_seed_investors = (\n",
    "    seed_help\n",
    "    .groupby('Company ID')['Investor ID']\n",
    "    .nunique()\n",
    "    .rename('Number Seed Investors')\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    num_seed_investors,\n",
    "    on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "companies['Number Seed Investors'] = companies['Number Seed Investors'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946fe7320a719be",
   "metadata": {},
   "source": [
    "#### Binary for Regional Investor and Overregional Investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c962ebfba6c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:38.776127Z",
     "start_time": "2025-05-10T21:39:38.502870Z"
    }
   },
   "outputs": [],
   "source": [
    "regional = (\n",
    "    seed_help\n",
    "    .groupby('Company ID')['Local Investor']\n",
    "    .any()\n",
    "    .rename('Regional Seed Investor Binary')\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    ")\n",
    "\n",
    "overregional = (\n",
    "    seed_help\n",
    "    .groupby('Company ID')['Local Investor']\n",
    "    .apply(lambda x: (~x).any())\n",
    "    .rename('Overregional Seed Investor Binary')\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    ")\n",
    "\n",
    "companies = (\n",
    "    companies\n",
    "    .merge(regional, on='Company ID', how='left')\n",
    "    .merge(overregional, on='Company ID', how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740e447765de843",
   "metadata": {},
   "source": [
    "Number of Lead Investors and Binary for Regional and Overregional Investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263b8f1d118135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:38.967102Z",
     "start_time": "2025-05-10T21:39:38.806733Z"
    }
   },
   "outputs": [],
   "source": [
    "num_lead_seed_investors = (\n",
    "    seed_help[seed_help['Lead']]\n",
    "    .groupby('Company ID')['Investor ID']\n",
    "    .nunique()\n",
    "    .rename('Number Lead Seed Investors')\n",
    ")\n",
    "\n",
    "has_regional_lead = (\n",
    "    seed_help[seed_help['Lead']]\n",
    "    .groupby('Company ID')['Local Investor']\n",
    "    .any()\n",
    "    .rename('Regional Lead Seed Investor Binary')\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    ")\n",
    "\n",
    "has_overregional_lead = (\n",
    "    seed_help[seed_help['Lead']]\n",
    "    .groupby('Company ID')['Local Investor']\n",
    "    .apply(lambda x: (~x).any())\n",
    "    .rename('Overregional Lead Seed Investor Binary')\n",
    "    .fillna(False)\n",
    "    .astype(bool)\n",
    ")\n",
    "\n",
    "companies = (\n",
    "    companies\n",
    "    .merge(num_lead_seed_investors, on='Company ID', how='left')\n",
    "    .merge(has_regional_lead, on='Company ID', how='left')\n",
    "    .merge(has_overregional_lead, on='Company ID', how='left')\n",
    ")\n",
    "\n",
    "companies['Number Lead Seed Investors'] = companies['Number Lead Seed Investors'].fillna(0).astype(int)\n",
    "\n",
    "companies['Number Lead Seed Investors'] = companies['Number Lead Seed Investors'].fillna(0).astype(int)\n",
    "\n",
    "mask_no_lead = companies['Number Lead Seed Investors'] == 0\n",
    "companies.loc[mask_no_lead, 'Regional Lead Seed Investor Binary'] = False\n",
    "companies.loc[mask_no_lead, 'Overregional Lead Seed Investor Binary'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf147a2b3707ae9",
   "metadata": {},
   "source": [
    "#### Make the binaries to a boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6451402be69d0a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.018834Z",
     "start_time": "2025-05-10T21:39:38.998590Z"
    }
   },
   "outputs": [],
   "source": [
    "companies = companies.convert_dtypes()\n",
    "\n",
    "binary_cols = [\n",
    "    'Regional Seed Investor Binary',\n",
    "    'Overregional Seed Investor Binary',\n",
    "    'Regional Lead Seed Investor Binary',\n",
    "    'Overregional Lead Seed Investor Binary'\n",
    "]\n",
    "\n",
    "for col in binary_cols:\n",
    "    companies[col] = companies[col].fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f66ba53128ff7c",
   "metadata": {},
   "source": [
    "#### Average Age of Seed Investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ab560bb5e35c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.107225Z",
     "start_time": "2025-05-10T21:39:39.051234Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'Announced Date' not in seed_help.columns:\n",
    "    seed_help = seed_help.merge(\n",
    "        rounds[['Round ID', 'Announced Date']],\n",
    "        on='Round ID',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "seed_help['Announced Date']        = pd.to_datetime(seed_help['Announced Date'], errors='coerce')\n",
    "seed_help['Investor Founded Date'] = pd.to_datetime(seed_help['Investor Founded Date'], errors='coerce')\n",
    "\n",
    "seed_help['Investment Year']       = seed_help['Announced Date'].dt.year\n",
    "seed_help['Investor Founded Year'] = seed_help['Investor Founded Date'].dt.year\n",
    "\n",
    "seed_help['Investor Age at Investment'] = (\n",
    "    (seed_help['Investment Year'] - seed_help['Investor Founded Year'])\n",
    "    .clip(lower=0)\n",
    ")\n",
    "\n",
    "avg_age = (\n",
    "    seed_help\n",
    "    .groupby('Company ID')['Investor Age at Investment']\n",
    "    .mean()\n",
    "    .round(1)\n",
    "    .rename('Avg Age of Seed Investors')\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    avg_age,\n",
    "    on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "companies['Avg Age of Seed Investors'] = companies['Avg Age of Seed Investors'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de1b10e9f004b",
   "metadata": {},
   "source": [
    "#### Average Number of Exits of Seed Investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adf483287da4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.156433Z",
     "start_time": "2025-05-10T21:39:39.138304Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_exits = (\n",
    "    seed_help\n",
    "    .groupby('Company ID')['Number of Exits']\n",
    "    .mean()\n",
    "    .round(1)\n",
    "    .rename('Avg Exits of Seed Investors')\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    avg_exits,\n",
    "    on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "companies['Avg Exits of Seed Investors'] = companies['Avg Exits of Seed Investors'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0593975e6e06ca",
   "metadata": {},
   "source": [
    "#### Binary Industry Focused Investor in Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1868d24a39bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.206283Z",
     "start_time": "2025-05-10T21:39:39.187776Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_help['Specific VC Binary'] = (\n",
    "    seed_help['Specific VC Binary']\n",
    "    .astype('boolean')\n",
    ")\n",
    "\n",
    "industry_specific = (\n",
    "    seed_help\n",
    "    .groupby('Company ID')['Specific VC Binary']\n",
    "    .any()\n",
    "    .rename('Specific VC in Seed Binary')\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    industry_specific,\n",
    "    on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "companies['Specific VC in Seed Binary'] = (\n",
    "    companies['Specific VC in Seed Binary']\n",
    "    .fillna(False)\n",
    "    .astype('boolean')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ea09a5c72878c",
   "metadata": {},
   "source": [
    "#### Industry Specific VC in Seed Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c434bca8fa11c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.249422Z",
     "start_time": "2025-05-10T21:39:39.237917Z"
    }
   },
   "outputs": [],
   "source": [
    "industry_specific_lead = (\n",
    "    seed_help[seed_help['Lead'] & seed_help['Specific VC Binary']]\n",
    "    .groupby('Company ID')['Specific VC Binary']\n",
    "    .any()\n",
    "    .rename('Specific Lead VC in Seed Binary')\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    industry_specific_lead,\n",
    "    on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "companies['Specific Lead VC in Seed Binary'] = (\n",
    "    companies['Specific Lead VC in Seed Binary']\n",
    "    .fillna(False)\n",
    "    .astype('boolean')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f9d4fe",
   "metadata": {},
   "source": [
    "### Accelerator, Micro VC, Angel Group or Corporate Venture Capita in Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b61cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = [\n",
    "    \"Accelerator\",\n",
    "    \"Angel Group\",\n",
    "    \"Micro VC\",\n",
    "    \"Corporate Venture Capital\",\n",
    "]\n",
    "\n",
    "company_flags = (\n",
    "    seed_help\n",
    "    .groupby(\"Company ID\")[flags]\n",
    "    .any()   \n",
    "    .rename(columns=lambda c: f\"{c} Funding Binary\")\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    company_flags,\n",
    "    on=\"Company ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "for col in company_flags.columns:\n",
    "    companies[col] = companies[col].fillna(False).astype(\"boolean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43422c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = [\n",
    "    \"Accelerator\",\n",
    "    \"Angel Group\",\n",
    "    \"Micro VC\",\n",
    "    \"Corporate Venture Capital\",\n",
    "]\n",
    "\n",
    "lead_rounds = seed_help[seed_help[\"Lead\"] == True]\n",
    "\n",
    "company_lead_flags = (\n",
    "    lead_rounds\n",
    "    .groupby(\"Company ID\")[flags]\n",
    "    .any() \n",
    "    .rename(columns=lambda c: f\"{c} Lead Funding Binary\")\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    company_lead_flags,\n",
    "    on=\"Company ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "for col in company_lead_flags.columns:\n",
    "    companies[col] = companies[col].fillna(False).astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96131b7d5912f58",
   "metadata": {},
   "source": [
    "#### Time to first Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cadc123028fbc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.305105Z",
     "start_time": "2025-05-10T21:39:39.282786Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'Investment Year' not in seed_help.columns:\n",
    "    seed_help['Investment Year'] = pd.to_datetime(\n",
    "        seed_help['Announced Date'], errors='coerce'\n",
    "    ).dt.year\n",
    "\n",
    "first_seed = (\n",
    "    seed_help\n",
    "    .groupby('Company ID')['Investment Year']\n",
    "    .min()\n",
    "    .rename('First Seed Year')\n",
    ")\n",
    "\n",
    "companies = companies.merge(\n",
    "    first_seed,\n",
    "    on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "companies['Years to Seed'] = (\n",
    "    (companies['First Seed Year'] - companies['Founded Year'])\n",
    "    .clip(lower=0)\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "companies.drop(columns=['First Seed Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c475cd9d9e278",
   "metadata": {},
   "source": [
    "## F: Success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1db74e29765151",
   "metadata": {},
   "source": [
    "In addition to the Exit Binary, another success for an VC investor is to get the company to a certain investment stage as it minimizes the risk of losing the investment. Therefore, we define certain stages where it is assumed as an successful investment. The stages are:\n",
    "\n",
    "- Series B\n",
    "- Series C\n",
    "- Series D\n",
    "- Series E\n",
    "- Series F\n",
    "- Series G\n",
    "- Private Equity with Last Equity Funding Amount (in USD) > 20,000,000\n",
    "- Post-IPO Equity with Last Equity Funding Amount (in USD) > 20,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894cd946828ab99",
   "metadata": {},
   "source": [
    "Look for unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b6a97aef094b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.601189Z",
     "start_time": "2025-05-10T21:39:39.597501Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_vals = companies['Last Equity Funding Type'].dropna().unique().tolist()\n",
    "print(unique_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd9574eb1d6187",
   "metadata": {},
   "source": [
    "Define Funding Success according to the rules set before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ab865a7bcf086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.646288Z",
     "start_time": "2025-05-10T21:39:39.638917Z"
    }
   },
   "outputs": [],
   "source": [
    "series_success = ['Series B', 'Series C', 'Series D', 'Series E', 'Series F', 'Series G']\n",
    "\n",
    "companies['Last Equity Funding Amount (in USD)'] = pd.to_numeric(\n",
    "    companies['Last Equity Funding Amount (in USD)'],\n",
    "    errors='coerce'\n",
    ").fillna(0)\n",
    "\n",
    "companies['Funding Success'] = (\n",
    "    companies['Last Equity Funding Type'].isin(series_success) |\n",
    "    (\n",
    "        (companies['Last Equity Funding Type'] == 'Private Equity') &\n",
    "        (companies['Last Equity Funding Amount (in USD)'] > 20_000_000)\n",
    "    ) |\n",
    "    (\n",
    "        (companies['Last Equity Funding Type'] == 'Post-IPO Equity') &\n",
    "        (companies['Last Equity Funding Amount (in USD)'] > 20_000_000)\n",
    "    )\n",
    ").astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f089a4876851c5",
   "metadata": {},
   "source": [
    "Define Success binary / boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2232ae8f4514ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.694880Z",
     "start_time": "2025-05-10T21:39:39.683683Z"
    }
   },
   "outputs": [],
   "source": [
    "companies['Success'] = (\n",
    "    companies['Exit Binary'].fillna(False) |\n",
    "    companies['Funding Success'].fillna(False)\n",
    ").astype(bool)\n",
    "\n",
    "cols = [c for c in companies.columns if c not in ['Exit Binary', 'Success']]\n",
    "new_order = cols + ['Exit Binary', 'Success']\n",
    "companies = companies[new_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984784046ef15f0",
   "metadata": {},
   "source": [
    "## G: Prepare Companies Data Frame for Analysis in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9bbeb525aad87",
   "metadata": {},
   "source": [
    "Delete companies without founding round due to errors in Crunchbase filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee5c3dbc2cb5ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.789997Z",
     "start_time": "2025-05-10T21:39:39.780952Z"
    }
   },
   "outputs": [],
   "source": [
    "companies = companies[companies['Number Seed Rounds'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e819fd2e4591c246",
   "metadata": {},
   "source": [
    "Create country as a control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80afd64d64a9dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.865925Z",
     "start_time": "2025-05-10T21:39:39.825531Z"
    }
   },
   "outputs": [],
   "source": [
    "companies['Headquarters Country'] = companies['Headquarters Location'].str.split(',').str[-1].str.strip()\n",
    "\n",
    "insert_at = companies.columns.get_loc('Headquarters Location') + 1\n",
    "companies.insert(insert_at, 'Headquarters Country', companies.pop('Headquarters Country'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097f0f1eaa57a1d",
   "metadata": {},
   "source": [
    "Only select companies from a certain year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffd5e1297d3bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:39.911624Z",
     "start_time": "2025-05-10T21:39:39.901706Z"
    }
   },
   "outputs": [],
   "source": [
    "start_year = 2007\n",
    "end_year = 2025\n",
    "\n",
    "companies = companies[companies['Founded Year'].between(start_year, end_year)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6eea0cfdc7d99",
   "metadata": {},
   "source": [
    "## H: Create an investor data frame\n",
    "Based on the investments in the time frame and prepare it for R analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9892ee01850ab2",
   "metadata": {},
   "source": [
    "Aggregate features for the investors based on their investment behaviours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae6f61580eb54d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:43.828208Z",
     "start_time": "2025-05-10T21:39:39.947631Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_help_enriched = seed_help.merge(\n",
    "    companies[['Company ID', 'Industry Groups', 'Founded Year', 'Success', 'Hub Binary', 'Number Seed Rounds', 'Headquarters Country']],\n",
    "    on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "investor_aggregates = seed_help_enriched.groupby('Investor ID').agg(\n",
    "    Number_of_Seed_Investments              = ('Round ID', 'nunique'),\n",
    "    Number_of_Companies_Invested            = ('Company ID', 'nunique'),\n",
    "    Number_of_Unique_Industries_Invested    = ('Industry Groups',\n",
    "                                               lambda x: x.str.get_dummies(sep=',').sum().gt(0).sum()),\n",
    "    Average_Company_Age_at_Investment       = ('Organization Founded Year',\n",
    "                                               lambda x: (seed_help_enriched['Investment Year'] - x).mean()),\n",
    "    Number_of_Successful_Investments        = ('Success', 'sum'),\n",
    "    Number_of_Local_Investments             = ('Local Investor', 'sum'),\n",
    "    Average_Investment_Distance             = ('Distance km', 'mean'),\n",
    "    Number_of_Investments_in_Hubs           = ('Hub Binary', 'sum'),\n",
    "    Average_Number_of_Seed_Rounds           = ('Number Seed Rounds', 'mean'),\n",
    "    Industry_Specific_Investments           = ('Specific VC Binary', 'sum'),\n",
    "    Number_of_Unique_Countries_Invested     = ('Headquarters Country', 'nunique'),\n",
    "    Number_of_Investments_with_Fundraising_Success = ('Success', 'sum'),\n",
    "    Number_of_Lead_Seed_Investments         = ('Lead', 'sum')          \n",
    ").reset_index()\n",
    "\n",
    "rename_features = {\n",
    "    'Number_of_Seed_Investments':               'Seed Investments Count',\n",
    "    'Number_of_Companies_Invested':             'Unique Companies Count',\n",
    "    'Number_of_Unique_Industries_Invested':     'Unique Industries Count',\n",
    "    'Average_Company_Age_at_Investment':        'Avg Company Age at Investment',\n",
    "    'Number_of_Successful_Investments':         'Successful Investments Count',\n",
    "    'Number_of_Local_Investments':              'Local Investments Count',\n",
    "    'Average_Investment_Distance':              'Avg Investment Distance (km)',\n",
    "    'Number_of_Investments_in_Hubs':            'Hub Investments Count',\n",
    "    'Average_Number_of_Seed_Rounds':            'Avg Seed Rounds per Company',\n",
    "    'Industry_Specific_Investments':            'Specific Investments Count',\n",
    "    'Number_of_Unique_Countries_Invested':      'Unique Countries Count',\n",
    "    'Number_of_Investments_with_Fundraising_Success': 'Fundraising Success Count',\n",
    "    'Number_of_Lead_Seed_Investments':          'Seed Lead Investments Count'  \n",
    "}\n",
    "\n",
    "investor_aggregates.rename(columns=rename_features, inplace=True)\n",
    "\n",
    "investors_seed = investors.merge(investor_aggregates, on='Investor ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680b62dba0f8049",
   "metadata": {},
   "source": [
    "Select needed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6b404ce62575a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:43.875854Z",
     "start_time": "2025-05-10T21:39:43.869126Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_columns = investors_seed.select_dtypes(include=['float64', 'int64']).columns\n",
    "investors_seed[numeric_columns] = investors_seed[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "required_columns = [\n",
    "    'Investor ID', 'Organization/Person Name', 'Organization/Person Name URL', 'Description', 'Location',\n",
    "    'Seed Investments Count', 'Seed Lead Investments Count', 'Unique Companies Count', 'Unique Industries Count',\n",
    "    'Local Investments Count', 'Avg Investment Distance (km)', 'Hub Investments Count',\n",
    "    'Unique Countries Count', 'Fundraising Success Count', 'Successful Investments Count', 'Specific VC Binary', 'Accelerator', 'Corporate Venture Capital', 'Micro VC', 'Angel Group'\n",
    "]\n",
    "\n",
    "investors_seed = investors_seed[required_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d77776b41266a",
   "metadata": {},
   "source": [
    "Create Country variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f96ed724da59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:43.922714Z",
     "start_time": "2025-05-10T21:39:43.916595Z"
    }
   },
   "outputs": [],
   "source": [
    "investors_seed['Country'] = investors_seed['Location'].str.split(',').str[-1].str.strip()\n",
    "\n",
    "insert_at = investors_seed.columns.get_loc('Location') + 1\n",
    "investors_seed.insert(insert_at, 'Country', investors_seed.pop('Country'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b685df8be84a69",
   "metadata": {},
   "source": [
    "Create Median Distance, create the local investor variable, and implement restriction on the data quality (seed investment not NaN and Avg Investment Distance not NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae56f7b19bed183",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:43.968573Z",
     "start_time": "2025-05-10T21:39:43.961503Z"
    }
   },
   "outputs": [],
   "source": [
    "investors_seed['Local Investor'] = investors_seed['Avg Investment Distance (km)'] < 100\n",
    "\n",
    "investors_seed = investors_seed.dropna(subset=['Seed Investments Count'])\n",
    "\n",
    "investors_seed = investors_seed.dropna(subset=['Avg Investment Distance (km)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3565577",
   "metadata": {},
   "source": [
    "Primary Role in Investments (based on the majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_counts = (\n",
    "    seed_help\n",
    "    .groupby(\"Round ID\")[\"Investor ID\"]\n",
    "    .nunique()\n",
    "    .rename(\"num_investors\")\n",
    ")\n",
    "\n",
    "seed_help = seed_help.merge(round_counts, on=\"Round ID\", how=\"left\")\n",
    "\n",
    "def assign_role(row):\n",
    "    if row[\"Lead\"]:\n",
    "        return \"Lead\"\n",
    "    else:\n",
    "        return \"Co-Investor\"\n",
    "\n",
    "seed_help[\"Syndication Role\"] = seed_help.apply(assign_role, axis=1)\n",
    "\n",
    "primary_roles = (\n",
    "    seed_help\n",
    "    .groupby(\"Investor ID\")[\"Syndication Role\"]\n",
    "    .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else pd.NA)\n",
    "    .rename(\"Primary Role\")\n",
    ")\n",
    "\n",
    "investors_seed = investors_seed.merge(\n",
    "    primary_roles,\n",
    "    on=\"Investor ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "investors_seed[\"Lead Investor\"] = investors_seed[\"Primary Role\"] == \"Lead\"\n",
    "\n",
    "investors_seed = investors_seed.drop(columns=[\"Primary Role\"])\n",
    "\n",
    "investors_seed[\"Lead Investor\"] = investors_seed[\"Lead Investor\"].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec151d99",
   "metadata": {},
   "source": [
    "Hub Investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "investors_seed[\"Hub Investor\"] = (\n",
    "    investors_seed[\"Hub Investments Count\"] /\n",
    "    investors_seed[\"Seed Investments Count\"]\n",
    ") > 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca423744eb7f1",
   "metadata": {},
   "source": [
    "Only select investors with at least a certain number of investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe816b29459be5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:44.030461Z",
     "start_time": "2025-05-10T21:39:44.024633Z"
    }
   },
   "outputs": [],
   "source": [
    "min_seed_investments = 1\n",
    "investors_seed = investors_seed[investors_seed['Seed Investments Count'] >= min_seed_investments]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26439ae46553c73",
   "metadata": {},
   "source": [
    "Ordering of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ef4b84bd8cd97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:44.078612Z",
     "start_time": "2025-05-10T21:39:44.075104Z"
    }
   },
   "outputs": [],
   "source": [
    "logical_order = [\n",
    "    'Investor ID', 'Organization/Person Name', 'Organization/Person Name URL', 'Location', 'Country', 'Accelerator', 'Angel Group', 'Micro VC', \n",
    "    'Corporate Venture Capital', 'Specific VC Binary', 'Local Investor', 'Hub Investor', 'Lead Investor', 'Seed Investments Count', 'Seed Lead Investments Count', \n",
    "    'Unique Companies Count', 'Unique Industries Count', 'Local Investments Count', 'Avg Investment Distance (km)', 'Hub Investments Count',\n",
    "    'Unique Countries Count', 'Fundraising Success Count', 'Successful Investments Count'\n",
    "]\n",
    "investors_seed = investors_seed[logical_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305205f909f5646",
   "metadata": {},
   "source": [
    "Final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1bad2c4ac390d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:44.133350Z",
     "start_time": "2025-05-10T21:39:44.124671Z"
    }
   },
   "outputs": [],
   "source": [
    "investors_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e2602bd502118",
   "metadata": {},
   "source": [
    "## I: Save the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_types = [\"Pre-Seed\", \"Seed\", \"Angel\"]\n",
    "rounds_filtered = rounds[rounds[\"Funding Type\"].isin(keep_types)].copy()\n",
    "rounds_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f910a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_seed = companies.copy()\n",
    "\n",
    "to_move = [\n",
    "    \"Administrative Services\", \"Advertising\", \"Agriculture and Farming\",\n",
    "    \"Apps\", \"Artificial Intelligence (AI)\", \"Biotechnology\",\n",
    "    \"Blockchain and Cryptocurrency\", \"Clothing and Apparel\",\n",
    "    \"Commerce and Shopping\", \"Community and Lifestyle\",\n",
    "    \"Consumer Electronics\", \"Consumer Goods\", \"Content and Publishing\",\n",
    "    \"Data and Analytics\", \"Design\", \"Education\", \"Energy\", \"Events\",\n",
    "    \"Financial Services\", \"Food and Beverage\", \"Gaming\",\n",
    "    \"Government and Military\", \"Hardware\", \"Health Care\",\n",
    "    \"Information Technology\", \"Internet Services\",\n",
    "    \"Lending and Investments\", \"Manufacturing\", \"Media and Entertainment\",\n",
    "    \"Messaging and Telecommunications\", \"Mobile\", \"Music and Audio\",\n",
    "    \"Natural Resources\", \"Navigation and Mapping\", \"Other\", \"Payments\",\n",
    "    \"Platforms\", \"Privacy and Security\", \"Professional Services\",\n",
    "    \"Real Estate\", \"Sales and Marketing\", \"Science and Engineering\",\n",
    "    \"Social Impact\", \"Software\", \"Sports\", \"Sustainability\",\n",
    "    \"Transportation\", \"Travel and Tourism\", \"Video\"\n",
    "]\n",
    "\n",
    "\n",
    "cols_to_move = [c for c in to_move if c in companies_seed.columns]\n",
    "\n",
    "new_order = [c for c in companies_seed.columns if c not in cols_to_move] + cols_to_move\n",
    "\n",
    "companies_seed = companies_seed[new_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036fb8d6",
   "metadata": {},
   "source": [
    "Make sure that at least one investor is known for a round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7942cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_investor_ids = investors_seed['Investor ID'].unique()\n",
    "seed_help = seed_help[seed_help['Investor ID'].isin(valid_investor_ids)]\n",
    "\n",
    "valid_company_ids = seed_help['Company ID'].unique()\n",
    "\n",
    "initial_company_count = companies_seed['Company ID'].nunique()\n",
    "print(f\"Initial number of companies in companies_seed: {initial_company_count}\")\n",
    "\n",
    "companies_seed = companies_seed[companies_seed['Company ID'].isin(valid_company_ids)]\n",
    "\n",
    "final_company_count = companies_seed['Company ID'].nunique()\n",
    "print(f\"Final number of companies in companies_seed: {final_company_count}\")\n",
    "\n",
    "dropped_company_count = initial_company_count - final_company_count\n",
    "print(f\"Number of companies dropped: {dropped_company_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d17c358e25d78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T21:39:44.805510Z",
     "start_time": "2025-05-10T21:39:44.598391Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = 'data/sets-for-r/investors_seed.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True) \n",
    "investors_seed.to_csv(output_path, index=False)\n",
    "\n",
    "output_path = 'data/sets-for-r/companies_seed.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  \n",
    "companies_seed.to_csv(output_path, index=False)\n",
    "\n",
    "output_path = 'data/sets-for-r/seed_help.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)  \n",
    "seed_help.to_csv(output_path, index=False)\n",
    "\n",
    "output_path = 'data/sets-for-r/rounds.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "rounds_filtered.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
